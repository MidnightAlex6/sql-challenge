# SQL Challenge

![image](https://user-images.githubusercontent.com/126301312/235184768-099093f5-38ef-4032-9377-8ef12855bb89.png)

## Background

It’s been two weeks since you were hired as a new data engineer at Pewlett Hackard (a fictional company). Your first major task is to do a research project about people whom the company employed during the 1980s and 1990s. All that remains of the employee database from that period are six CSV files.

For this project, you’ll design the tables to hold the data from the CSV files, import the CSV files into a SQL database, and then answer questions about the data. That is, you’ll perform data modeling, data engineering, and data analysis, respectively.

## Files

Listed are the files used for this assignment

 * departments.csv
 * dept_emp.csv
 * dept_manager.csv
 * employees.csv
 * salaries.csv
 * titles.csv

## Instructions

This Challenge is divided into three parts: data modeling, data engineering, and data analysis.

## Data Modeling

Inspect the CSV files, and then sketch an Entity Relationship Diagram of the tables. To create the sketch, feel free to use a tool like QuickDBD.

## Data Engineering


Use the provided information to create a table schema for each of the six CSV files. Be sure to do the following:


Remember to specify the data types, primary keys, foreign keys, and other constraints.


For the primary keys, verify that the column is unique. Otherwise, create a composite key, which takes two primary keys to uniquely identify a row.


Be sure to create the tables in the correct order to handle the foreign keys.




Import each CSV file into its corresponding SQL table.
